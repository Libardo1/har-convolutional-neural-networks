{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "This notebook gathers the machine learning pipeline for training and testing the various models found on `/models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available gpus []\n"
     ]
    }
   ],
   "source": [
    "# generic imports\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "from subprocess import call\n",
    "import telegram_send\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras import layers, optimizers\n",
    "from keras.layers import Add, Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, Conv1D, MaxPooling1D, MaxPooling2D, Dropout, ELU, AveragePooling2D\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "\n",
    "from utils import terminate, outdir, load_dataset, show_stats, ohe_to_label, conf_matrix, export_model, f1\n",
    "from models import m_1d, m_1d2d, m_1d2d_01, m_1d2d_01_reg, m_3d, m_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################\n",
    "##    CONFIG    ##\n",
    "##################\n",
    "models_conf = {\n",
    "    'm_1d': {\n",
    "        'active': False,\n",
    "        'is_1d': True,\n",
    "        'model': m_1d\n",
    "    },\n",
    "    'm_3d': {\n",
    "        'active': False,\n",
    "        'is_1d': False,\n",
    "        'model': m_3d\n",
    "    },\n",
    "    'm_1d2d': {\n",
    "        'active': False,\n",
    "        'is_1d': False,\n",
    "        'model': m_1d2d\n",
    "    },\n",
    "    'm_1d2d_01': {\n",
    "        'active': False,\n",
    "        'is_1d': False,\n",
    "        'model': m_1d2d_01\n",
    "    },\n",
    "    'm_1d2d_01_reg': {\n",
    "        'active': True,\n",
    "        'is_1d': False,\n",
    "        'model': m_1d2d_01_reg\n",
    "    },\n",
    "    'm_resnet': {\n",
    "        'active': False,\n",
    "        'is_1d': False,\n",
    "        'model': m_resnet\n",
    "    }\n",
    "}\n",
    "\n",
    "# in datasets name, test and train gets prependend at load time\n",
    "general_conf = {\n",
    "    'debug': True,\n",
    "    'prod': False,\n",
    "    'export_models': False,\n",
    "    'batch_size': 64,\n",
    "    'iterations': 1,\n",
    "    'datasets': [\n",
    "        '',\n",
    "        #'-augmented',\n",
    "        #'-with-trans'\n",
    "    ]\n",
    "}\n",
    "\n",
    "class_conversion = {\n",
    "    '0': 'falling',\n",
    "    '1': 'jumping',\n",
    "    '2': 'lying',\n",
    "    '3': 'running',\n",
    "    '4': 'sitting',\n",
    "    '5': 'standing',\n",
    "    '6': 'walking'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### STARTING JOB for dataset  ###\n",
      "\n",
      "number of training examples = 22836\n",
      "number of test examples = 5709\n",
      "X_train shape: (22836, 128, 6)\n",
      "Y_train shape: (22836, 7)\n",
      "X_test shape: (5709, 128, 6)\n",
      "Y_test shape: (5709, 7)\n",
      "\n",
      "Model summary for m_1d2d_01_reg\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 128, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 16, 125, 6)        80        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 125, 6)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 122, 6)        2080      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 122, 6)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 122, 6)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 64, 120, 6)        6208      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 120, 6)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 64, 120, 6)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 120, 6)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 120, 6)        0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 64, 60, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 64, 60, 3)         24640     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 60, 3)         0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 64, 30, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 64, 30, 1)         24640     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 30, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 30, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 150)               288150    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 7)                 1057      \n",
      "=================================================================\n",
      "Total params: 383,783\n",
      "Trainable params: 383,783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "##   TRAINING   ##\n",
    "##################\n",
    "datasets_nr = len(general_conf['datasets'])\n",
    "models_nr = sum([t['active'] for t in models_conf.values()])\n",
    "total_cycles = datasets_nr * models_nr\n",
    "cycle = 1\n",
    "\n",
    "# cycle through the datasets\n",
    "for data in general_conf['datasets']:\n",
    "    print()\n",
    "    print('### STARTING JOB for dataset {} ###'.format(data))\n",
    "    print()\n",
    "    \n",
    "    X_train_o, X_test_o, Y_train, Y_test = load_dataset(data)\n",
    "    \n",
    "    # cycle through the models\n",
    "    for model_name, model in models_conf.items():\n",
    "        # output name identified by model name and dataset name\n",
    "        out_name = model_name + data\n",
    "        \n",
    "        if model['active']:\n",
    "            # reshape dataset if needed\n",
    "            input_shape = []\n",
    "            if model['is_1d']:\n",
    "                K.set_image_data_format('channels_last')\n",
    "                X_train, X_test = X_train_o, X_test_o\n",
    "                input_shape = [X_train.shape[1], X_train.shape[2]]\n",
    "            else:\n",
    "                # using channel_first because channel_last has a bug when used with gpu\n",
    "                # https://github.com/keras-team/keras/issues/10648\n",
    "                # with channel first the input has to be\n",
    "                # (batch, channels, rows, cols), so something like (12000, 1, 128, 6)\n",
    "                K.set_image_data_format('channels_first')\n",
    "                X_train = X_train_o.reshape(X_train_o.shape[0], 1, X_train_o.shape[1], X_train_o.shape[2])\n",
    "                X_test = X_test_o.reshape(X_test_o.shape[0], 1, X_test_o.shape[1], X_test_o.shape[2])\n",
    "                \n",
    "                # these are to be used if I'm using channel_last\n",
    "                # X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "                # X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "                \n",
    "                input_shape = [X_train.shape[1], X_train.shape[2], X_train.shape[3]]\n",
    "            \n",
    "            current_model = model['model'](input_shape)\n",
    "            #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "            current_model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy', f1])\n",
    "            print()\n",
    "            print('Model summary for', model_name)\n",
    "            print(current_model.summary())\n",
    "\n",
    "            # if debug is on, stop here and just show the model specifications\n",
    "            if not general_conf['debug']:\n",
    "                print('Starting training for model', out_name)\n",
    "                start_time = time.time()\n",
    "                callbacks = [\n",
    "                    # tensorboard config\n",
    "                    TensorBoard(log_dir='./logs/{}'.format(out_name), histogram_freq=0, write_graph=True, write_images=True),\n",
    "                    # stop if loss does not decrease after x epochs\n",
    "                    EarlyStopping(patience=30, monitor='val_loss', min_delta=0, mode='min'),\n",
    "                    # save best model\n",
    "                    ModelCheckpoint('{}-weights.h5'.format(outdir(out_name)), monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "                ]\n",
    "                \n",
    "                # train\n",
    "                history = current_model.fit(\n",
    "                    x = X_train, y = Y_train,\n",
    "                    epochs=general_conf['iterations'],\n",
    "                    batch_size=general_conf['batch_size'],\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    callbacks = callbacks)\n",
    "                # load best weights\n",
    "                current_model.load_weights('{}-weights.h5'.format(outdir(out_name)))\n",
    "                # test\n",
    "                preds = current_model.evaluate(x = X_test, y = Y_test)\n",
    "                show_stats(start_time, preds)\n",
    "                \n",
    "                # output results\n",
    "                predictions = current_model.predict(X_test)\n",
    "                Y_pred = ohe_to_label(predictions)\n",
    "                Y_true = ohe_to_label(Y_test)\n",
    "                \n",
    "                conf_matrix(Y_true, Y_pred, class_conversion, out_name, save = True)\n",
    "                \n",
    "                # export model\n",
    "                if general_conf['export_models']:\n",
    "                    export_model(current_model, out_name)\n",
    "                # notify\n",
    "                telegram_send.send(['Training {}/{} finished'.format(cycle, total_cycles)])\n",
    "            cycle += 1\n",
    "                \n",
    "# send finish signal via telegram and close aws instance\n",
    "if general_conf['prod']:\n",
    "    terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To import and explore a trained model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('modelname.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.summary()\n",
    "loaded_model.get_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
