{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generic imports\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from transforms3d.axangles import axangle2mat\n",
    "\n",
    "sns.set(style=\"white\", context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys of the dict element 59\n",
      "\n",
      "Keys:\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'ARS_Maria_Real_Sitting_Heading_2', 'ARS_Maria_Real_Sitting_Heading_3', 'ARS_Maria_Real_Sitting_Heading_4', 'ARS_Maria_FLGUp1', 'ARS_Maria_FLGUp2', 'ARS_Maria_FLGUp3', 'ARS_Maria_FLGUp4', 'ARS_Maria_Jump', 'ARS_Cristina_Test_4_Sensor_Left', 'ARS_Cristina_Test_5_Sensor_Left', 'ARS_Cristina_Test_2_Sensor_Left', 'ARS_Cristina_Test_3_Sensor_Left', 'ARS_Cristina_Test_1_Sensor_Left', 'ARS_Elena_Test_1_Sensor_Right', 'ARS_Elena_Test_2_Sensor_Right', 'ARS_Elena_Test_3_Sensor_Right', 'ARS_Elena_Test_4_Sensor_Right', 'ARS_Elena_Test_5_Sensor_Right', 'ARS_Elena_Walking', 'ARS_Fabian_Test_1_Sensor_Right', 'ARS_Fabian_Test_2_Sensor_Right', 'ARS_Fabian_Test_3_Sensor_Right', 'ARS_Fabian_Test_4_Sensor_Right', 'ARS_Fabian_Test_5_Sensor_Right', 'ARS_Jesus_Test_1_Sensor_Right', 'ARS_Jesus_Test_2_Sensor_Right', 'ARS_Jesus_Test_3_Inverse_Sensor_Right', 'ARS_Jesus_Test_4_Sensor_Right', 'ARS_Jesus_Test_5_Sensor_Right', 'ARS_Korbinian_Test_1_Sensor_Right', 'ARS_Korbinian_Test_3_Sensor_Right', 'ARS_Korbinian_Test_4_Sensor_Right', 'ARS_Korbinian_Test_5_Sensor_Right', 'ARS_Korbinian_Test_2_Sensor_Right', 'ARS_Maria_Falling_Sited_Heading_2', 'ARS_Maria_Falling_Sited_Heading_4', 'ARS_Maria_Real_Lying', 'ARS_Maria_Test_1', 'ARS_Maria_Falling_Sited_Heading_3', 'ARS_Maria_Falling_Sited_Heading_1', 'ARS_Maria_Real_Sitting_Heading_1', 'ARS_Maria_Running_Heading_1', 'ARS_Maria_Running_Heading_2', 'ARS_Maria_Real_Walking_Heading_1', 'ARS_Maria_Real_Walking_Heading_2', 'ARS_Maria_Real_Walking_Heading_3', 'ARS_Maria_Real_Walking_Heading_4', 'ARS_Maria_Real_Walking_Shoes_Sandals', 'ARS_Maria_Walking_Up_Down_Fast', 'ARS_Maria_Walking_Up_Down_Real', 'ARS_Maria_Running', 'ARS_Michael_Test_4_Sensor_Right_Pocket', 'ARS_Michael_Test_5_Sensor_Right_Pocket', 'ARS_Michael_Test_2_Sensor_Right_Pocket', 'ARS_Michael_Test_3_Sensor_Right_Pocket', 'ARS_Michael_Test_1_Sensor_Right_Pocket'])\n"
     ]
    }
   ],
   "source": [
    "# create the dataset from matlab file\n",
    "mat = scipy.io.loadmat('dataset-orig/ARS_DLR_DataSet.mat', squeeze_me=True, struct_as_record=True)\n",
    "print('Number of keys of the dict element', len(mat.keys()))\n",
    "print()\n",
    "print('Keys:')\n",
    "print(mat.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what a single entry is composed of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([[  4.53400000e+01,  -9.43000200e+00,   1.97339400e+00, ...,\n",
       "          4.93577200e-01,  -1.54302400e-01,   3.48073800e-01],\n",
       "       [  4.53500000e+01,  -9.42630400e+00,   1.96610800e+00, ...,\n",
       "          4.94766900e-01,  -1.55703100e-01,   3.46810900e-01],\n",
       "       [  4.53600000e+01,  -9.43360500e+00,   1.96788500e+00, ...,\n",
       "          4.93788400e-01,  -1.54264800e-01,   3.47441300e-01],\n",
       "       ..., \n",
       "       [  5.26090000e+02,  -8.37665400e+00,   4.48864500e+00, ...,\n",
       "          4.22742800e-01,  -2.76599000e-01,   4.07902500e-01],\n",
       "       [  5.26100000e+02,  -8.40929300e+00,   4.50478200e+00, ...,\n",
       "          4.21581900e-01,  -2.75860100e-01,   4.08134000e-01],\n",
       "       [  5.26110000e+02,  -8.39455000e+00,   4.49753500e+00, ...,\n",
       "          4.22797100e-01,  -2.75629300e-01,   4.08713200e-01]]),\n",
       "       array([[  4.53400000e+01,  -2.38955600e-01,   9.77489600e-02, ...,\n",
       "          8.65125200e-01,   4.73254700e-01,  -1.66097400e-01],\n",
       "       [  4.53500000e+01,  -2.38969200e-01,   9.78752400e-02, ...,\n",
       "          8.65118300e-01,   4.73285300e-01,  -1.66045700e-01],\n",
       "       [  4.53600000e+01,  -2.38768800e-01,   9.79371900e-02, ...,\n",
       "          8.65264900e-01,   4.73073200e-01,  -1.65886100e-01],\n",
       "       ..., \n",
       "       [  5.26090000e+02,  -9.69879400e-02,   5.03802200e-01, ...,\n",
       "          9.58142800e-01,  -1.86141700e-01,  -2.17516600e-01],\n",
       "       [  5.26100000e+02,  -9.68112900e-02,   5.03931200e-01, ...,\n",
       "          9.58223200e-01,  -1.85997300e-01,  -2.17285900e-01],\n",
       "       [  5.26110000e+02,  -9.66741500e-02,   5.03979700e-01, ...,\n",
       "          9.58257300e-01,  -1.85986900e-01,  -2.17144200e-01]]),\n",
       "       array(['STNDING', 'SITTING', 'STNDING'], dtype=object),\n",
       "       array([    1,  7743,  8388, 45040, 45929, 48078], dtype=uint16)], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entry = mat[list(mat.keys())[3]]\n",
    "example_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a single frame recorded by the IMU sensor is like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.53400000e+01,  -9.43000200e+00,   1.97339400e+00,\n",
       "        -1.57358700e+00,  -5.30050200e-02,   4.51815800e-02,\n",
       "         3.52342500e-02,   4.93577200e-01,  -1.54302400e-01,\n",
       "         3.48073800e-01])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entry[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the corresponding attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45.34      ,  -0.2389556 ,   0.09774896,  -0.966098  ,\n",
       "        -0.4409745 ,   0.8754856 ,   0.1976519 ,   0.8651252 ,\n",
       "         0.4732547 ,  -0.1660974 ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entry[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the dataset documentation, this is what each column represent:\n",
    "\n",
    "**`example_entry[0]`**\n",
    "\n",
    "* 1st column is the time extracted from the sensor in seconds. For example: a value 15.6 means that it has passed 15.6 seconds since the sensor started to transmit data.\n",
    "\n",
    "\n",
    "* 2nd column is the acceleration in the X axis measured by the sensor.\n",
    "* 3rd column is the acceleration in the Y axis measured by the sensor.\n",
    "* 4th column is the acceleration in the Z axis measured by the sensor.\n",
    "\n",
    "\n",
    "* 5th column is the angular velocity in the X axis measured by the sensor.\n",
    "* 6th column is the angular velocity in the Y axis measured by the sensor.\n",
    "* 7th column is the angular velocity in the Z axis measured by the sensor.\n",
    "\n",
    "\n",
    "* 8th column is the magnetic field in the X axis measured by the sensor.\n",
    "* 9th column is the magnetic field in the Y axis measured by the sensor.\n",
    "* 10th column is the magnetic field in the Z axis measured by the sensor.\n",
    "\n",
    "**`example_entry[1]`**\n",
    "\n",
    "Contains a matrix of double data with the direction cosine matrix extracted from the sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STNDING' 'SITTING' 'STNDING']\n",
      "[    1  7743  8388 45040 45929 48078]\n"
     ]
    }
   ],
   "source": [
    "print(example_entry[2])\n",
    "print(example_entry[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`example_entry[2]`**\n",
    "\n",
    "It contains a cell array where every position is a string. Every string is the identifier of the activity. The possible values of this strings are:\n",
    "* 'RUNNING' = \"running\"\n",
    "* 'WALKING' = \"walking\"\n",
    "* 'WALKUPS' = \"walking upstairs\"\n",
    "* 'WALKDWS' = \"walking downstairs\"\n",
    "* 'STNDING' = \"standing\"\n",
    "* 'SITTING' = \"sitting\"\n",
    "* 'XLYINGX' = \"lying on the floor\"\n",
    "* 'FALLING' = \"falling\"\n",
    "* 'JUMPVRT' = \"jumping vertically\"\n",
    "* 'JUMPFWD' = \"jumping forward\"\n",
    "* 'JUMPBCK' = \"jumping backward\"\n",
    "* 'TRANSIT' = \"transition between the activities\"\n",
    "\n",
    "As an example, if the cell contains three strings as: \"STNDING RUNNING STNDING\" means that the person performed these three activities in this \torder.\n",
    "\n",
    "**`example_entry[3]`**\n",
    "\n",
    "It is a vector with the index of the rows that indicate the beginning and ending of an activity. The format is the following:\n",
    "\n",
    "```\n",
    "\tt1_0 t1_f t2_0 t2_f t3_0 t3_f t4_0 t4_f ... tn_0 tn_f\n",
    "\n",
    "\tti_0 for i=1...n contains the beginning of the activity i.\n",
    "\tti_f for i=1...n contains the ending of the activity i.\n",
    "```\n",
    "\n",
    "Notice that the length of this vector should be twice the length of the cell containing the strings with the activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration file\n",
    "To store the settings needed to create the output datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    # fill transients with interpolated activities\n",
    "    # if this is true, remove_transients should be false\n",
    "    'fill_transients': False,\n",
    "    'remove_transients': True,\n",
    "    'adapted_labels_colname': 'adapted_labels',\n",
    "    'out_filename': 'boh',\n",
    "    'convert_to_gf': False,\n",
    "    'normalize_sensor': True,\n",
    "    'frame_window': 128,\n",
    "    'frame_stride': 64,\n",
    "    'augment_sensors': True,\n",
    "    'augment_factor': 0.35\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From matlab to pandas\n",
    "Lets convert it to a dataframe for later processing.\n",
    "\n",
    "We have 3 datasets available: `ARS_DLR_DataSet.mat`, `ARS_DLR_DataSet_V2.mat`, `ARS_DLR_Benchmark_Data_Set.mat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializations\n",
    "# renaming activities\n",
    "activity_map = {\n",
    "    'RUNNING': 'running',\n",
    "    'WALKING': 'walking',\n",
    "    'JUMPING': 'jumping',\n",
    "    'STNDING': 'standing',\n",
    "    'SITTING': 'sitting',\n",
    "    'XLYINGX': 'lying',\n",
    "    'FALLING': 'falling',\n",
    "    'TRANSUP': 'TRANS-getting up',\n",
    "    'TRANSDW': 'TRANS-going down',\n",
    "    'TRNSACC': 'TRANS-accelerating',\n",
    "    'TRNSDCC': 'TRANS-deccelerating',\n",
    "    'TRANSIT': 'TRANS-other',\n",
    "    'WALKUPS': 'walking upstairs',\n",
    "    'WALKDWS': 'walking downstairs',\n",
    "    'JUMPVRT': 'jumping vertically',\n",
    "    'JUMPFWD': 'jumping forward',\n",
    "    'JUMPBCK': 'jumping backward'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'person': [],\n",
    "    'acc_x': [],\n",
    "    'acc_y': [],\n",
    "    'acc_z': [],\n",
    "    'gyr_x': [],\n",
    "    'gyr_y': [],\n",
    "    'gyr_z': [],\n",
    "    'attitude': [],\n",
    "    'labels': []\n",
    "}\n",
    "\n",
    "datasets = ['ARS_DLR_DataSet.mat', 'ARS_DLR_DataSet_V2.mat', 'ARS_DLR_Benchmark_Data_Set.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mislableing error found, length 88 21920\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    mat = scipy.io.loadmat('dataset-orig/{}'.format(dataset), squeeze_me=True, struct_as_record=True)\n",
    "    keys = [k for k in mat.keys() if k[0] != '_']\n",
    "    for j, k in enumerate(keys):\n",
    "        \"\"\"\n",
    "        if j < 11:\n",
    "            continue\n",
    "        \"\"\"\n",
    "        record = mat[k]\n",
    "        sensor = record[0]\n",
    "        attitude = record[1]\n",
    "        labels = record[2]\n",
    "        frame_ranges = record[3]\n",
    "        '''\n",
    "        print('### DEBUG - {} ###'.format(k))\n",
    "        print(labels)\n",
    "        print(frame_ranges)\n",
    "        '''\n",
    "        # cycle through the labels\n",
    "        for i in range(0, len(frame_ranges), 2):\n",
    "            # create current label\n",
    "            label_index = math.floor(i/2)\n",
    "            label = labels[label_index]\n",
    "            label = activity_map[label]\n",
    "            # +1 because extremes are included\n",
    "            frame_length = frame_ranges[i+1] - frame_ranges[i] +1\n",
    "            data['labels'] += [label] * frame_length\n",
    "\n",
    "            # manually create labels for transitions\n",
    "            # if subsequent frame_range is not contiguous, create transition\n",
    "            if (i+2 < len(frame_ranges)) and (frame_ranges[i+2] > frame_ranges[i+1]+1):\n",
    "                #print('dentro', frame_ranges[i+2], frame_ranges[i+1]+1)\n",
    "                frame_length = frame_ranges[i+2] - frame_ranges[i+1] -1\n",
    "                # labeling transitions with current and subsequent actions\n",
    "                current_action, next_action = (activity_map[labels[label_index]], activity_map[labels[label_index+1]])\n",
    "                label = 'TRANS-{}-{}'.format(current_action, next_action)\n",
    "                data['labels'] += [label] * frame_length\n",
    "            # this below case represent a mislabling error\n",
    "            elif (i+2 < len(frame_ranges)) and (frame_ranges[i+2] < frame_ranges[i+1]+1):\n",
    "                print('mislableing error found, length', frame_ranges[i+1]-frame_ranges[i+2], frame_ranges[i+1])\n",
    "                frame_ranges[i+2] = frame_ranges[i+1]+1\n",
    "                \"\"\"\n",
    "                frame_length = frame_ranges[i+1] - frame_ranges[i+2] -1\n",
    "                # labeling transitions with current and subsequent actions\n",
    "                label = labels[label_index]\n",
    "                data['labels'] += [label] * frame_length\n",
    "                \"\"\"\n",
    "\n",
    "        # sensor[:, 0] indicates time which is not useful, columns 7: are magnetometer, not useful\n",
    "        # using list concatenation instead of numpy arrays is more efficient\n",
    "        data['acc_x'] += sensor[:, 1].tolist()\n",
    "        data['acc_y'] += sensor[:, 2].tolist()\n",
    "        data['acc_z'] += sensor[:, 3].tolist()\n",
    "        data['gyr_x'] += sensor[:, 4].tolist()\n",
    "        data['gyr_y'] += sensor[:, 5].tolist()\n",
    "        data['gyr_z'] += sensor[:, 6].tolist()\n",
    "\n",
    "        data['attitude'] += attitude[:, 1:].tolist()\n",
    "        data['person'] += [k] * len(sensor[:, 1])\n",
    "\n",
    "        \"\"\"\n",
    "        print(j)\n",
    "        print(len(data['acc_x']))\n",
    "        print(len(data['labels']))\n",
    "        print(labels, len(labels))\n",
    "        print(frame_ranges, len(frame_ranges))\n",
    "        if j == 11:\n",
    "            break\n",
    "        \"\"\"\n",
    "    \n",
    "df = pd.DataFrame(data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>attitude</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>labels</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.430002</td>\n",
       "      <td>1.973394</td>\n",
       "      <td>-1.573587</td>\n",
       "      <td>[-0.2389556, 0.09774896, -0.966098, -0.4409745...</td>\n",
       "      <td>-0.053005</td>\n",
       "      <td>0.045182</td>\n",
       "      <td>0.035234</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.426304</td>\n",
       "      <td>1.966108</td>\n",
       "      <td>-1.573818</td>\n",
       "      <td>[-0.2389692, 0.09787524, -0.9660817, -0.440980...</td>\n",
       "      <td>-0.055009</td>\n",
       "      <td>0.052240</td>\n",
       "      <td>0.061471</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.433605</td>\n",
       "      <td>1.967885</td>\n",
       "      <td>-1.577345</td>\n",
       "      <td>[-0.2387688, 0.09793719, -0.966125, -0.4408015...</td>\n",
       "      <td>-0.034780</td>\n",
       "      <td>0.030520</td>\n",
       "      <td>0.050830</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.433682</td>\n",
       "      <td>1.956968</td>\n",
       "      <td>-1.603091</td>\n",
       "      <td>[-0.2389078, 0.09797277, -0.966087, -0.4408588...</td>\n",
       "      <td>-0.060378</td>\n",
       "      <td>0.067733</td>\n",
       "      <td>0.059497</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.437164</td>\n",
       "      <td>1.944125</td>\n",
       "      <td>-1.599782</td>\n",
       "      <td>[-0.2390312, 0.0980841, -0.9660453, -0.4409559...</td>\n",
       "      <td>-0.074121</td>\n",
       "      <td>0.052016</td>\n",
       "      <td>0.067737</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x     acc_y     acc_z  \\\n",
       "0 -9.430002  1.973394 -1.573587   \n",
       "1 -9.426304  1.966108 -1.573818   \n",
       "2 -9.433605  1.967885 -1.577345   \n",
       "3 -9.433682  1.956968 -1.603091   \n",
       "4 -9.437164  1.944125 -1.599782   \n",
       "\n",
       "                                            attitude     gyr_x     gyr_y  \\\n",
       "0  [-0.2389556, 0.09774896, -0.966098, -0.4409745... -0.053005  0.045182   \n",
       "1  [-0.2389692, 0.09787524, -0.9660817, -0.440980... -0.055009  0.052240   \n",
       "2  [-0.2387688, 0.09793719, -0.966125, -0.4408015... -0.034780  0.030520   \n",
       "3  [-0.2389078, 0.09797277, -0.966087, -0.4408588... -0.060378  0.067733   \n",
       "4  [-0.2390312, 0.0980841, -0.9660453, -0.4409559... -0.074121  0.052016   \n",
       "\n",
       "      gyr_z    labels                            person  \n",
       "0  0.035234  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "1  0.061471  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "2  0.050830  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "3  0.059497  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "4  0.067737  standing  ARS_Maria_Real_Sitting_Heading_2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2188965, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the current labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standing                                       724542\n",
       "walking                                        369227\n",
       "sitting                                        353225\n",
       "lying                                          169309\n",
       "running                                         90294\n",
       "walking upstairs                                34574\n",
       "TRANS-standing-falling                          29139\n",
       "walking downstairs                              29079\n",
       "jumping                                         28440\n",
       "TRANS-getting up                                24153\n",
       "TRANS-lying-falling                             21466\n",
       "TRANS-standing-walking upstairs                 21149\n",
       "TRANS-falling-standing                          20582\n",
       "TRANS-standing-sitting                          19460\n",
       "TRANS-walking-standing                          16328\n",
       "TRANS-walking downstairs-standing               14559\n",
       "TRANS-TRANS-going down-TRANS-getting up         14360\n",
       "TRANS-standing-running                          14044\n",
       "TRANS-standing-jumping forward                  13184\n",
       "falling                                         11902\n",
       "TRANS-running-standing                          11552\n",
       "TRANS-sitting-walking                           10552\n",
       "TRANS-going down                                 9910\n",
       "TRANS-walking upstairs-walking upstairs          9878\n",
       "TRANS-walking downstairs-walking downstairs      9109\n",
       "TRANS-falling-lying                              9006\n",
       "TRANS-accelerating                               8576\n",
       "TRANS-jumping vertically-standing                8125\n",
       "TRANS-lying-standing                             7215\n",
       "jumping vertically                               6357\n",
       "TRANS-sitting-standing                           6353\n",
       "jumping forward                                  5909\n",
       "TRANS-walking upstairs-walking downstairs        5384\n",
       "TRANS-standing-walking                           5307\n",
       "TRANS-standing-standing                          5199\n",
       "jumping backward                                 4788\n",
       "TRANS-jumping forward-standing                   4689\n",
       "TRANS-jumping backward-standing                  4654\n",
       "TRANS-jumping forward-jumping forward            4367\n",
       "TRANS-jumping vertically-jumping backward        4291\n",
       "TRANS-standing-jumping vertically                3771\n",
       "TRANS-standing-jumping backward                  3659\n",
       "TRANS-sitting-TRANS-getting up                   3430\n",
       "TRANS-TRANS-getting up-standing                  3350\n",
       "TRANS-jumping forward-jumping vertically         3128\n",
       "TRANS-walking upstairs-standing                  2572\n",
       "TRANS-deccelerating                              2294\n",
       "TRANS-standing-lying                             1807\n",
       "TRANS-jumping-standing                           1590\n",
       "TRANS-standing-walking downstairs                1546\n",
       "TRANS-jumping vertically-jumping vertically       650\n",
       "TRANS-TRANS-going down-sitting                    424\n",
       "TRANS-jumping-jumping                             328\n",
       "TRANS-running-TRANS-deccelerating                 179\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_counts = df['labels'].value_counts()\n",
    "#activity_counts.loc[~activity_counts.index.str.startswith('TRANS')]\n",
    "activity_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets merge together some activities:\n",
    "* jumping forward, jumping, jumping backward, jumping vertically = jumping\n",
    "* walking upstairs, walking downstairs, walking = walking\n",
    "\n",
    "And then for an initial analysis lets *not* consider the transition periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['labels'] = df['labels'].where(~df['labels'].isin(['jumping forward', 'jumping backward', 'jumping vertically']), 'jumping')\n",
    "df['labels'] = df['labels'].where(~df['labels'].isin(['walking upstairs', 'walking downstairs']), 'walking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 361319 transition frames, at 100Hz they are approx 60min of data\n"
     ]
    }
   ],
   "source": [
    "# check how many transients there are, before removing them from the dataset\n",
    "trans_count = df.loc[df['labels'].str.startswith('TRANS')].shape[0]\n",
    "print('There are {} transition frames, at 100Hz they are approx {}min of data'.format(trans_count, round(trans_count/100/60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the transients\n",
    "if config['remove_transients']:\n",
    "    df = df.loc[~df['labels'].str.startswith('TRANS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flattens a nested list\n",
    "def flatten_list(arr):\n",
    "    return [item for sublist in arr for item in sublist]\n",
    "\n",
    "# replace transients with action labels\n",
    "def fill_transients(df, column_name):\n",
    "    transitions = df['labels'].str.startswith('TRANS')\n",
    "            #positions = df.index.values\n",
    "    transitions_index = df.loc[transitions].index\n",
    "\n",
    "    # create a nested list with groups referred to\n",
    "    # to each single transition block\n",
    "    transitions_nested = []\n",
    "    temp_arr = []\n",
    "    for i in transitions_index:\n",
    "        if len(temp_arr) == 0:\n",
    "            temp_arr.append(i)\n",
    "            continue\n",
    "        # if still in the current activity block\n",
    "        if i == temp_arr[-1]+1:\n",
    "            temp_arr.append(i)\n",
    "        else:\n",
    "            # new activity block found, store current activity block\n",
    "            transitions_nested.append(temp_arr)\n",
    "            # and reset temp array with current value\n",
    "            temp_arr = [i]\n",
    "    transitions_nested.append(temp_arr)\n",
    "    \n",
    "    # just to check everything went right\n",
    "    transitions_flat = flatten_list(transitions_nested)\n",
    "    for i, t in enumerate(transitions_index):\n",
    "        if i >= len(transitions_flat):\n",
    "            raise ValueError('Out of bound for flattened list at', i)\n",
    "            break\n",
    "        if t != transitions_flat[i]:\n",
    "            raise ValueError('Value {} at position {} was skipped'.format(t, i))\n",
    "            break\n",
    "    \n",
    "    # print(len(flat_list))\n",
    "    # print(len(transitions_index))\n",
    "    \n",
    "    adapted_labels = []\n",
    "    for trans_block in transitions_nested:\n",
    "        # get section length\n",
    "        activity_len = len(trans_block)\n",
    "        # get previous and following activity\n",
    "        activity_prev = df.iloc[trans_block[0]-1]['labels']\n",
    "        activity_foll = df.iloc[trans_block[-1]+1]['labels']\n",
    "        # half transient associated to prev activity and half to following\n",
    "        half = math.floor(activity_len/2)\n",
    "        adapted_labels.extend([activity_prev] * half)\n",
    "        adapted_labels.extend([activity_foll] * (activity_len-half))\n",
    "    \n",
    "    # copy labels column and store \n",
    "    df[column_name] = df['labels']\n",
    "    df[column_name].iloc[transitions_flat] = adapted_labels\n",
    "    \n",
    "    return df\n",
    "\n",
    "label_column_name = 'labels' if not config['fill_transients'] else config['adapted_labels_colname']\n",
    "if config['fill_transients']:\n",
    "    df = fill_transients(df, config['adapted_labels_colname'])\n",
    "    # just to check how many more values have been added to the dataset\n",
    "    print((df[config['adapted_labels_colname']].value_counts() - df['labels'].value_counts()).sort_values().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standing    121.0\n",
       "walking      72.0\n",
       "sitting      59.0\n",
       "lying        28.0\n",
       "running      15.0\n",
       "jumping       8.0\n",
       "falling       2.0\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minutes of each activity\n",
    "# 100 because it's recorded at 100Hz\n",
    "round(df[label_column_name].value_counts() / 100 / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the sensor measures in the global frame\n",
    "def to_global_frame(row):\n",
    "    attitude = np.array(row['attitude']).reshape(3,3)\n",
    "    acceleration = np.array([row.acc_x, row.acc_y, row.acc_z])\n",
    "    gyro = np.array([row.gyr_x, row.gyr_y, row.gyr_z])\n",
    "    \n",
    "    # global frame conversions\n",
    "    acc_gf = np.dot(attitude.T, acceleration)\n",
    "    gyro_gf = np.dot(attitude.T, gyro)\n",
    "    \n",
    "    # replace previous sensor values with new ones on the gf\n",
    "    row['acc_x'] = acc_gf[0]\n",
    "    row['acc_y'] = acc_gf[1]\n",
    "    row['acc_z'] = acc_gf[2]\n",
    "    \n",
    "    row['gyr_x'] = gyro_gf[0]\n",
    "    row['gyr_y'] = gyro_gf[1]\n",
    "    row['gyr_z'] = gyro_gf[2]\n",
    "    \n",
    "    return row\n",
    "\n",
    "if config['convert_to_gf']:\n",
    "    df = df.apply(to_global_frame, axis=1)\n",
    "    df = df.drop('attitude', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize acceleration and gyroscope\n",
    "def normalize_sensors(column):\n",
    "    return (column-column.mean())/column.std()\n",
    "\n",
    "if config['normalize_sensor']:\n",
    "    columns_to_norm = [\n",
    "        'acc_x', 'acc_y', 'acc_z',\n",
    "        'gyr_x', 'gyr_y', 'gyr_z']\n",
    "    df[columns_to_norm] = df[columns_to_norm].apply(normalize_sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to test in future\n",
    "* ~~keep transients~~\n",
    "* ~~normalizing sensor values~~\n",
    "* ~~data augmentation of underrepresented classes~~\n",
    "* test with global frame\n",
    "* reduce sampling rate to a value lower than 100Hz\n",
    "* variable frame size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# append zeros if there is space left at the end of the frame\n",
    "def append_zeros(df, stride, window):\n",
    "    label = df[label_column_name].iloc[0]\n",
    "    if df.shape[0] > window:\n",
    "        n = math.floor((df.shape[0]-window)/stride) + 1\n",
    "        remain = stride * n - (df.shape[0] - window)\n",
    "    else:\n",
    "        remain = window - df.shape[0]\n",
    "    #print('have to add {} zeros'.format(remain))\n",
    "    # create the correct nr of zero valued rows and set corresponding label\n",
    "    df_padded = pd.DataFrame(data = np.zeros((remain, df.shape[1])), columns=df.columns)\n",
    "    df_padded[label_column_name] = label\n",
    "    # append zeroed rows on bottom of the dataframe\n",
    "    return df.append(df_padded)\n",
    "\n",
    "def framing_range(start, end, stride, window, initialize=False):\n",
    "    if initialize:\n",
    "        return 0, start+window\n",
    "    # updates start and end positions considering stride and window size\n",
    "    start = end-stride\n",
    "    end = start+window\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = config['frame_window']\n",
    "stride = config['frame_stride']\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# cycle through each unique activity\n",
    "activities = df[label_column_name].unique()\n",
    "for activity in activities:\n",
    "    #print('doing ', activity)\n",
    "    df_activity = df.loc[df[label_column_name] == activity]\n",
    "    #print('shape is', df_activity.shape)\n",
    "    \n",
    "    # check if padding is needed\n",
    "    if df_activity.shape[0] % stride != 0:\n",
    "        df_activity = append_zeros(df_activity, stride, window)\n",
    "    #print('shape after is', df_activity.shape)\n",
    "        \n",
    "    start, end = framing_range(0, 0, stride, window, initialize=True)\n",
    "    # until current activity is exhausted\n",
    "    while end != df_activity.shape[0]:\n",
    "        # get appropriate frame of current activity block\n",
    "        current = df_activity.iloc[start:end]\n",
    "        data = np.dstack([\n",
    "            current['acc_x'],\n",
    "            current['acc_y'],\n",
    "            current['acc_z'],\n",
    "            current['gyr_x'],\n",
    "            current['gyr_y'],\n",
    "            current['gyr_z']\n",
    "            ])\n",
    "        # using lists for performance\n",
    "        x += data.tolist()\n",
    "        y += [activity] * data.shape[0]\n",
    "        # update start and end window indexes\n",
    "        start, end = framing_range(start, end, stride, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28545, 128, 6)\n",
      "28545\n"
     ]
    }
   ],
   "source": [
    "# check if the dimensions are coherent\n",
    "print(np.array(x).shape)\n",
    "print(len(y))\n",
    "assert np.array(x).shape[0] == len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(x), y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22836, 128, 6) 22836\n",
      "(5709, 128, 6) 5709\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, len(y_train))\n",
    "print(x_test.shape, len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if train-test splitting was successful and kept classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>standing</th>\n",
       "      <td>0.396532</td>\n",
       "      <td>0.396567</td>\n",
       "      <td>0.396523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walking</th>\n",
       "      <td>0.236889</td>\n",
       "      <td>0.236819</td>\n",
       "      <td>0.236907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sitting</th>\n",
       "      <td>0.193309</td>\n",
       "      <td>0.193204</td>\n",
       "      <td>0.193335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lying</th>\n",
       "      <td>0.092626</td>\n",
       "      <td>0.092661</td>\n",
       "      <td>0.092617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running</th>\n",
       "      <td>0.049361</td>\n",
       "      <td>0.049396</td>\n",
       "      <td>0.049352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumping</th>\n",
       "      <td>0.024838</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>0.024829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>falling</th>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.006437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              full      test     train\n",
       "standing  0.396532  0.396567  0.396523\n",
       "walking   0.236889  0.236819  0.236907\n",
       "sitting   0.193309  0.193204  0.193335\n",
       "lying     0.092626  0.092661  0.092617\n",
       "running   0.049361  0.049396  0.049352\n",
       "jumping   0.024838  0.024873  0.024829\n",
       "falling   0.006446  0.006481  0.006437"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = {\n",
    "    'full': pd.Series(y),\n",
    "    'train': pd.Series(y_train),\n",
    "    'test': pd.Series(y_test)\n",
    "}\n",
    "\n",
    "pd.DataFrame(ys).apply(pd.value_counts).apply(lambda col: col/col.sum())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ys_train = pd.Series(y_train)\n",
    "ys_train.value_counts()/ys_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ys_test = pd.Series(y_train)\n",
    "ys_test.value_counts()/ys_test.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class proportions are maintained both in test and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set data augmentation\n",
    "The goal is to augment each class proportionally to how well its class is represented.\n",
    "\n",
    "Each class must have a number of samples at least equal to 35% of the most represented class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some transformation functions\n",
    "\n",
    "# X must be in form time * features_nr\n",
    "# es. (3600, 6)\n",
    "\n",
    "# apply a rotation along a random axis\n",
    "def DA_Rotation(X):\n",
    "    X_acc = X[:,:3]\n",
    "    X_gyr = X[:,3:]\n",
    "    # axis to apply the rotation to\n",
    "    axis = np.random.uniform(low=-1, high=1, size=X_acc.shape[1])\n",
    "    # rotation entity\n",
    "    angle = np.random.uniform(low=-np.pi, high=np.pi)\n",
    "    X_acc_rotated = np.matmul(X_acc, axangle2mat(axis,angle))\n",
    "    X_gyr_rotated = np.matmul(X_gyr , axangle2mat(axis,angle))\n",
    "    return np.hstack([X_acc_rotated, X_gyr_rotated])\n",
    "\n",
    "# permute window segments partitions along the time axis\n",
    "# simply divide the window in n_perm sections and swap\n",
    "# their places\n",
    "def DA_Permutation(X, n_perm = 5):\n",
    "    arr = []\n",
    "    segment_len = math.floor(X.shape[0]/n_perm)\n",
    "    for i in range(0, n_perm):\n",
    "        start = i*segment_len\n",
    "        end = X.shape[0] if i == n_perm-1 else start+segment_len\n",
    "        arr += [np.arange(start, end).tolist()]\n",
    "    arr = np.random.permutation(arr)\n",
    "    arr = [item for sublist in arr for item in sublist]\n",
    "    return X[arr, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes have to be augmented by this number of values\n",
      "lying      1054\n",
      "running    2042\n",
      "jumping    2602\n",
      "falling    3022\n",
      "dtype: int64\n",
      "Shape of the augmented sensor values\n",
      "(8720, 128, 6)\n",
      "Final shape of the training set and labels\n",
      "(31556, 128, 6) 31556\n",
      "Check if the labels are now more balanced\n",
      "standing    9055\n",
      "walking     5410\n",
      "sitting     4415\n",
      "lying       3169\n",
      "jumping     3169\n",
      "falling     3169\n",
      "running     3169\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if config['augment_sensors']:\n",
    "    ys_train = pd.Series(y_train)\n",
    "    # each class must have at least config.augment_factor % of elements\n",
    "    # of the most represented class\n",
    "    lower_bound = int(ys_train.value_counts().max() * config['augment_factor'])\n",
    "    # number of elements needed for each class to be balanced\n",
    "    augment_amount = lower_bound - ys_train.value_counts()\n",
    "    augment_amount = augment_amount[augment_amount>0]\n",
    "    print('Classes have to be augmented by this number of values')\n",
    "    print(augment_amount)\n",
    "    \n",
    "    # cycle through the index of classes to augment\n",
    "    augmented_values = []\n",
    "    labels = []\n",
    "    # index represent the name of the label/activity\n",
    "    for activity in augment_amount.index:\n",
    "        # get indexes corresponding to the current activity\n",
    "        x_indexes = ys_train[ys_train == activity].index\n",
    "        # cycle the nr of augmentations to do for this class\n",
    "        for i in range(0, augment_amount[activity]):\n",
    "            randint = np.random.randint(0, len(x_indexes))\n",
    "            current_index = x_indexes[randint]\n",
    "            # get a random sample from the framed dataset\n",
    "            window_sample = x_train[current_index]\n",
    "            \n",
    "            # apply transformations\n",
    "            rotate = DA_Rotation(window_sample)\n",
    "            permute = DA_Permutation(window_sample)\n",
    "            \n",
    "            # span acc and gyr in depth so to end up with a dimension (?, window_size, 6)\n",
    "            #print('uno')\n",
    "            augmented_values += permute.reshape(1, permute.shape[0], permute.shape[1]).tolist()\n",
    "            labels.append(activity)\n",
    "\n",
    "    augmented_values = np.array(augmented_values)\n",
    "    print('Shape of the augmented sensor values')\n",
    "    print(augmented_values.shape)\n",
    "    #print(len(labels))\n",
    "    \n",
    "    # attach the augmented data to the training and test datasets\n",
    "    x_train = np.vstack([x_train, augmented_values])\n",
    "    y_train.extend(labels)\n",
    "    \n",
    "    print('Final shape of the training set and labels')\n",
    "    print(x_train.shape, len(y_train))\n",
    "    \n",
    "    print('Check if the labels are now more balanced')\n",
    "    print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### THIS FUNCTION HAS BEEN REPLACED ATM #####\n",
    "# permute window segments partitions along the time axis\n",
    "def DA_Permutation(X, n_perm = 4):\n",
    "    arr = []\n",
    "    segment_len = math.floor(X.shape[0]/n_perm)\n",
    "    start = 0\n",
    "    end = segment_len\n",
    "    for i in range(0, n_perm):\n",
    "        # in last iteration, get elements until the end\n",
    "        if i == n_perm-1:\n",
    "            end = X.shape[0]\n",
    "        arr += [X[start:end, :].tolist()]\n",
    "        start = end\n",
    "        end += segment_len\n",
    "    arr = np.random.permutation(arr)\n",
    "    arr = [item for sublist in arr for item in sublist]\n",
    "    return np.array(arr)\n",
    "X = np.random.randint(0,10,48).reshape(-1,6)\n",
    "print(X)\n",
    "arr = DA_Permutation(X)\n",
    "print()\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train with one hot encoding dimension check\n",
      "(31556, 7)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding of the labels\n",
    "def one_hot_encode(y):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_int_encoded = le.fit_transform(y)\n",
    "    y_int_encoded = np.array(y_int_encoded).reshape(len(y_int_encoded), 1)\n",
    "    ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "    y_ohe = ohe.fit_transform(y_int_encoded)\n",
    "    return y_ohe\n",
    "y_train_ohe = one_hot_encode(y_train)\n",
    "y_test_ohe = one_hot_encode(y_test)\n",
    "\n",
    "print('y_train with one hot encoding dimension check')\n",
    "print(y_train_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving all the files\n",
    "with h5py.File('datasets/train-{}.h5'.format(config['out_filename']), 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=x_train)\n",
    "    hf.create_dataset(\"y\",  data=y_train_ohe)\n",
    "with h5py.File('datasets/test-{}.h5'.format(config['out_filename']), 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=x_test)\n",
    "    hf.create_dataset(\"y\",  data=y_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31556, 7) (31556, 7)\n",
      "(31556, 128, 6) (31556, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('datasets/train-{}.h5'.format(config['out_filename']), 'r') as hf:\n",
    "    x = hf['x'][:]\n",
    "    y = hf['y'][:]\n",
    "print(y.shape, y_train_ohe.shape)\n",
    "print(x.shape, x_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
