{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generic imports\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "sns.set(style=\"white\", context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys of the dict element 59\n",
      "\n",
      "Keys:\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'ARS_Maria_Real_Sitting_Heading_2', 'ARS_Maria_Real_Sitting_Heading_3', 'ARS_Maria_Real_Sitting_Heading_4', 'ARS_Maria_FLGUp1', 'ARS_Maria_FLGUp2', 'ARS_Maria_FLGUp3', 'ARS_Maria_FLGUp4', 'ARS_Maria_Jump', 'ARS_Cristina_Test_4_Sensor_Left', 'ARS_Cristina_Test_5_Sensor_Left', 'ARS_Cristina_Test_2_Sensor_Left', 'ARS_Cristina_Test_3_Sensor_Left', 'ARS_Cristina_Test_1_Sensor_Left', 'ARS_Elena_Test_1_Sensor_Right', 'ARS_Elena_Test_2_Sensor_Right', 'ARS_Elena_Test_3_Sensor_Right', 'ARS_Elena_Test_4_Sensor_Right', 'ARS_Elena_Test_5_Sensor_Right', 'ARS_Elena_Walking', 'ARS_Fabian_Test_1_Sensor_Right', 'ARS_Fabian_Test_2_Sensor_Right', 'ARS_Fabian_Test_3_Sensor_Right', 'ARS_Fabian_Test_4_Sensor_Right', 'ARS_Fabian_Test_5_Sensor_Right', 'ARS_Jesus_Test_1_Sensor_Right', 'ARS_Jesus_Test_2_Sensor_Right', 'ARS_Jesus_Test_3_Inverse_Sensor_Right', 'ARS_Jesus_Test_4_Sensor_Right', 'ARS_Jesus_Test_5_Sensor_Right', 'ARS_Korbinian_Test_1_Sensor_Right', 'ARS_Korbinian_Test_3_Sensor_Right', 'ARS_Korbinian_Test_4_Sensor_Right', 'ARS_Korbinian_Test_5_Sensor_Right', 'ARS_Korbinian_Test_2_Sensor_Right', 'ARS_Maria_Falling_Sited_Heading_2', 'ARS_Maria_Falling_Sited_Heading_4', 'ARS_Maria_Real_Lying', 'ARS_Maria_Test_1', 'ARS_Maria_Falling_Sited_Heading_3', 'ARS_Maria_Falling_Sited_Heading_1', 'ARS_Maria_Real_Sitting_Heading_1', 'ARS_Maria_Running_Heading_1', 'ARS_Maria_Running_Heading_2', 'ARS_Maria_Real_Walking_Heading_1', 'ARS_Maria_Real_Walking_Heading_2', 'ARS_Maria_Real_Walking_Heading_3', 'ARS_Maria_Real_Walking_Heading_4', 'ARS_Maria_Real_Walking_Shoes_Sandals', 'ARS_Maria_Walking_Up_Down_Fast', 'ARS_Maria_Walking_Up_Down_Real', 'ARS_Maria_Running', 'ARS_Michael_Test_4_Sensor_Right_Pocket', 'ARS_Michael_Test_5_Sensor_Right_Pocket', 'ARS_Michael_Test_2_Sensor_Right_Pocket', 'ARS_Michael_Test_3_Sensor_Right_Pocket', 'ARS_Michael_Test_1_Sensor_Right_Pocket'])\n"
     ]
    }
   ],
   "source": [
    "# create the dataset from matlab file\n",
    "mat = scipy.io.loadmat('dataset/ARS_DLR_DataSet.mat', squeeze_me=True, struct_as_record=True)\n",
    "print('Number of keys of the dict element', len(mat.keys()))\n",
    "print()\n",
    "print('Keys:')\n",
    "print(mat.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what a single entry is composed of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([[  4.53400000e+01,  -9.43000200e+00,   1.97339400e+00, ...,\n",
       "          4.93577200e-01,  -1.54302400e-01,   3.48073800e-01],\n",
       "       [  4.53500000e+01,  -9.42630400e+00,   1.96610800e+00, ...,\n",
       "          4.94766900e-01,  -1.55703100e-01,   3.46810900e-01],\n",
       "       [  4.53600000e+01,  -9.43360500e+00,   1.96788500e+00, ...,\n",
       "          4.93788400e-01,  -1.54264800e-01,   3.47441300e-01],\n",
       "       ..., \n",
       "       [  5.26090000e+02,  -8.37665400e+00,   4.48864500e+00, ...,\n",
       "          4.22742800e-01,  -2.76599000e-01,   4.07902500e-01],\n",
       "       [  5.26100000e+02,  -8.40929300e+00,   4.50478200e+00, ...,\n",
       "          4.21581900e-01,  -2.75860100e-01,   4.08134000e-01],\n",
       "       [  5.26110000e+02,  -8.39455000e+00,   4.49753500e+00, ...,\n",
       "          4.22797100e-01,  -2.75629300e-01,   4.08713200e-01]]),\n",
       "       array([[  4.53400000e+01,  -2.38955600e-01,   9.77489600e-02, ...,\n",
       "          8.65125200e-01,   4.73254700e-01,  -1.66097400e-01],\n",
       "       [  4.53500000e+01,  -2.38969200e-01,   9.78752400e-02, ...,\n",
       "          8.65118300e-01,   4.73285300e-01,  -1.66045700e-01],\n",
       "       [  4.53600000e+01,  -2.38768800e-01,   9.79371900e-02, ...,\n",
       "          8.65264900e-01,   4.73073200e-01,  -1.65886100e-01],\n",
       "       ..., \n",
       "       [  5.26090000e+02,  -9.69879400e-02,   5.03802200e-01, ...,\n",
       "          9.58142800e-01,  -1.86141700e-01,  -2.17516600e-01],\n",
       "       [  5.26100000e+02,  -9.68112900e-02,   5.03931200e-01, ...,\n",
       "          9.58223200e-01,  -1.85997300e-01,  -2.17285900e-01],\n",
       "       [  5.26110000e+02,  -9.66741500e-02,   5.03979700e-01, ...,\n",
       "          9.58257300e-01,  -1.85986900e-01,  -2.17144200e-01]]),\n",
       "       array(['STNDING', 'SITTING', 'STNDING'], dtype=object),\n",
       "       array([    1,  7743,  8388, 45040, 45929, 48078], dtype=uint16)], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entry = mat[list(mat.keys())[3]]\n",
    "example_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a single frame recorded by the IMU sensor is like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.53400000e+01,  -9.43000200e+00,   1.97339400e+00,\n",
       "        -1.57358700e+00,  -5.30050200e-02,   4.51815800e-02,\n",
       "         3.52342500e-02,   4.93577200e-01,  -1.54302400e-01,\n",
       "         3.48073800e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entry[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the corresponding attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45.34      ,  -0.2389556 ,   0.09774896,  -0.966098  ,\n",
       "        -0.4409745 ,   0.8754856 ,   0.1976519 ,   0.8651252 ,\n",
       "         0.4732547 ,  -0.1660974 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entry[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the dataset documentation, this is what each column represent:\n",
    "\n",
    "**`example_entry[0]`**\n",
    "\n",
    "* 1st column is the time extracted from the sensor in seconds. For example: a value 15.6 means that it has passed 15.6 seconds since the sensor started to transmit data.\n",
    "\n",
    "\n",
    "* 2nd column is the acceleration in the X axis measured by the sensor.\n",
    "* 3rd column is the acceleration in the Y axis measured by the sensor.\n",
    "* 4th column is the acceleration in the Z axis measured by the sensor.\n",
    "\n",
    "\n",
    "* 5th column is the angular velocity in the X axis measured by the sensor.\n",
    "* 6th column is the angular velocity in the Y axis measured by the sensor.\n",
    "* 7th column is the angular velocity in the Z axis measured by the sensor.\n",
    "\n",
    "\n",
    "* 8th column is the magnetic field in the X axis measured by the sensor.\n",
    "* 9th column is the magnetic field in the Y axis measured by the sensor.\n",
    "* 10th column is the magnetic field in the Z axis measured by the sensor.\n",
    "\n",
    "**`example_entry[1]`**\n",
    "\n",
    "Contains a matrix of double data with the direction cosine matrix extracted from the sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STNDING' 'SITTING' 'STNDING']\n",
      "[    1  7743  8388 45040 45929 48078]\n"
     ]
    }
   ],
   "source": [
    "print(example_entry[2])\n",
    "print(example_entry[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`example_entry[2]`**\n",
    "\n",
    "It contains a cell array where every position is a string. Every string is the identifier of the activity. The possible values of this strings are:\n",
    "* 'RUNNING' = \"running\"\n",
    "* 'WALKING' = \"walking\"\n",
    "* 'WALKUPS' = \"walking upstairs\"\n",
    "* 'WALKDWS' = \"walking downstairs\"\n",
    "* 'STNDING' = \"standing\"\n",
    "* 'SITTING' = \"sitting\"\n",
    "* 'XLYINGX' = \"lying on the floor\"\n",
    "* 'FALLING' = \"falling\"\n",
    "* 'JUMPVRT' = \"jumping vertically\"\n",
    "* 'JUMPFWD' = \"jumping forward\"\n",
    "* 'JUMPBCK' = \"jumping backward\"\n",
    "* 'TRANSIT' = \"transition between the activities\"\n",
    "\n",
    "As an example, if the cell contains three strings as: \"STNDING RUNNING STNDING\" means that the person performed these three activities in this \torder.\n",
    "\n",
    "**`example_entry[3]`**\n",
    "\n",
    "It is a vector with the index of the rows that indicate the beginning and ending of an activity. The format is the following:\n",
    "\n",
    "```\n",
    "\tt1_0 t1_f t2_0 t2_f t3_0 t3_f t4_0 t4_f ... tn_0 tn_f\n",
    "\n",
    "\tti_0 for i=1...n contains the beginning of the activity i.\n",
    "\tti_f for i=1...n contains the ending of the activity i.\n",
    "```\n",
    "\n",
    "Notice that the length of this vector should be twice the length of the cell containing the strings with the activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From matlab to pandas\n",
    "Lets convert it to a dataframe for later processing.\n",
    "\n",
    "We have 3 datasets available: `ARS_DLR_DataSet.mat`, `ARS_DLR_DataSet_V2.mat`, `ARS_DLR_Benchmark_Data_Set.mat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializations\n",
    "# renaming activities\n",
    "activity_map = {\n",
    "    'RUNNING': 'running',\n",
    "    'WALKING': 'walking',\n",
    "    'JUMPING': 'jumping',\n",
    "    'STNDING': 'standing',\n",
    "    'SITTING': 'sitting',\n",
    "    'XLYINGX': 'lying',\n",
    "    'FALLING': 'falling',\n",
    "    'TRANSUP': 'TRANS-getting up',\n",
    "    'TRANSDW': 'TRANS-going down',\n",
    "    'TRNSACC': 'TRANS-accelerating',\n",
    "    'TRNSDCC': 'TRANS-deccelerating',\n",
    "    'TRANSIT': 'TRANS-other',\n",
    "    'WALKUPS': 'walking upstairs',\n",
    "    'WALKDWS': 'walking downstairs',\n",
    "    'JUMPVRT': 'jumping vertically',\n",
    "    'JUMPFWD': 'jumping forward',\n",
    "    'JUMPBCK': 'jumping backward'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'person': [],\n",
    "    'acc_x': [],\n",
    "    'acc_y': [],\n",
    "    'acc_z': [],\n",
    "    'gyr_x': [],\n",
    "    'gyr_y': [],\n",
    "    'gyr_z': [],\n",
    "    'attitude': [],\n",
    "    'labels': []\n",
    "}\n",
    "\n",
    "datasets = ['ARS_DLR_DataSet.mat', 'ARS_DLR_DataSet_V2.mat', 'ARS_DLR_Benchmark_Data_Set.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mislableing error found, length 88 21920\n"
     ]
    }
   ],
   "source": [
    "for mat in datasets:\n",
    "    mat = scipy.io.loadmat('dataset/{}'.format(mat), squeeze_me=True, struct_as_record=True)\n",
    "    keys = [k for k in mat.keys() if k[0] != '_']\n",
    "    for j, k in enumerate(keys):\n",
    "        \"\"\"\n",
    "        if j < 11:\n",
    "            continue\n",
    "        \"\"\"\n",
    "        record = mat[k]\n",
    "        sensor = record[0]\n",
    "        attitude = record[1]\n",
    "        # cycle through the labels\n",
    "        labels = record[2]\n",
    "        frame_ranges = record[3]\n",
    "        '''\n",
    "        print('### DEBUG - {} ###'.format(k))\n",
    "        print(labels)\n",
    "        print(frame_ranges)\n",
    "        '''\n",
    "        for i in range(0, len(frame_ranges), 2):\n",
    "            # create current label\n",
    "            label_index = math.floor(i/2)\n",
    "            label = labels[label_index]\n",
    "            label = activity_map[label]\n",
    "            # +1 because extremes are included\n",
    "            frame_length = frame_ranges[i+1] - frame_ranges[i] +1\n",
    "            data['labels'] += [label] * frame_length\n",
    "\n",
    "            # manually create labels for transitions\n",
    "            # if subsequent frame_range is not contiguous, create transition\n",
    "            if (i+2 < len(frame_ranges)) and (frame_ranges[i+2] > frame_ranges[i+1]+1):\n",
    "                #print('dentro', frame_ranges[i+2], frame_ranges[i+1]+1)\n",
    "                frame_length = frame_ranges[i+2] - frame_ranges[i+1] -1\n",
    "                # labeling transitions with current and subsequent actions\n",
    "                current_action, next_action = (activity_map[labels[label_index]], activity_map[labels[label_index+1]])\n",
    "                label = 'TRANS-{}-{}'.format(current_action, next_action)\n",
    "                data['labels'] += [label] * frame_length\n",
    "            # this below case represent a mislabling error\n",
    "            elif (i+2 < len(frame_ranges)) and (frame_ranges[i+2] < frame_ranges[i+1]+1):\n",
    "                print('mislableing error found, length', frame_ranges[i+1]-frame_ranges[i+2], frame_ranges[i+1])\n",
    "                frame_ranges[i+2] = frame_ranges[i+1]+1\n",
    "                \"\"\"\n",
    "                frame_length = frame_ranges[i+1] - frame_ranges[i+2] -1\n",
    "                # labeling transitions with current and subsequent actions\n",
    "                label = labels[label_index]\n",
    "                data['labels'] += [label] * frame_length\n",
    "                \"\"\"\n",
    "\n",
    "        # sensor[:, 0] indicates time which is not useful, columns 7: are magnetometer, not useful\n",
    "        # using list instead of numpy concatenation is more efficient\n",
    "        data['acc_x'] += sensor[:, 1].tolist()\n",
    "        data['acc_y'] += sensor[:, 2].tolist()\n",
    "        data['acc_z'] += sensor[:, 3].tolist()\n",
    "        data['gyr_x'] += sensor[:, 4].tolist()\n",
    "        data['gyr_y'] += sensor[:, 5].tolist()\n",
    "        data['gyr_z'] += sensor[:, 6].tolist()\n",
    "\n",
    "        data['attitude'] += attitude[:, 1:].tolist()\n",
    "\n",
    "        data['person'] += [k] * len(sensor[:, 1])\n",
    "\n",
    "        \"\"\"\n",
    "        print(j)\n",
    "        print(len(data['acc_x']))\n",
    "        print(len(data['labels']))\n",
    "        print(labels, len(labels))\n",
    "        print(frame_ranges, len(frame_ranges))\n",
    "        if j == 11:\n",
    "            break\n",
    "        \"\"\"\n",
    "    \n",
    "df = pd.DataFrame(data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>attitude</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>labels</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.430002</td>\n",
       "      <td>1.973394</td>\n",
       "      <td>-1.573587</td>\n",
       "      <td>[-0.2389556, 0.09774896, -0.966098, -0.4409745...</td>\n",
       "      <td>-0.053005</td>\n",
       "      <td>0.045182</td>\n",
       "      <td>0.035234</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.426304</td>\n",
       "      <td>1.966108</td>\n",
       "      <td>-1.573818</td>\n",
       "      <td>[-0.2389692, 0.09787524, -0.9660817, -0.440980...</td>\n",
       "      <td>-0.055009</td>\n",
       "      <td>0.052240</td>\n",
       "      <td>0.061471</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.433605</td>\n",
       "      <td>1.967885</td>\n",
       "      <td>-1.577345</td>\n",
       "      <td>[-0.2387688, 0.09793719, -0.966125, -0.4408015...</td>\n",
       "      <td>-0.034780</td>\n",
       "      <td>0.030520</td>\n",
       "      <td>0.050830</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.433682</td>\n",
       "      <td>1.956968</td>\n",
       "      <td>-1.603091</td>\n",
       "      <td>[-0.2389078, 0.09797277, -0.966087, -0.4408588...</td>\n",
       "      <td>-0.060378</td>\n",
       "      <td>0.067733</td>\n",
       "      <td>0.059497</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.437164</td>\n",
       "      <td>1.944125</td>\n",
       "      <td>-1.599782</td>\n",
       "      <td>[-0.2390312, 0.0980841, -0.9660453, -0.4409559...</td>\n",
       "      <td>-0.074121</td>\n",
       "      <td>0.052016</td>\n",
       "      <td>0.067737</td>\n",
       "      <td>standing</td>\n",
       "      <td>ARS_Maria_Real_Sitting_Heading_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x     acc_y     acc_z  \\\n",
       "0 -9.430002  1.973394 -1.573587   \n",
       "1 -9.426304  1.966108 -1.573818   \n",
       "2 -9.433605  1.967885 -1.577345   \n",
       "3 -9.433682  1.956968 -1.603091   \n",
       "4 -9.437164  1.944125 -1.599782   \n",
       "\n",
       "                                            attitude     gyr_x     gyr_y  \\\n",
       "0  [-0.2389556, 0.09774896, -0.966098, -0.4409745... -0.053005  0.045182   \n",
       "1  [-0.2389692, 0.09787524, -0.9660817, -0.440980... -0.055009  0.052240   \n",
       "2  [-0.2387688, 0.09793719, -0.966125, -0.4408015... -0.034780  0.030520   \n",
       "3  [-0.2389078, 0.09797277, -0.966087, -0.4408588... -0.060378  0.067733   \n",
       "4  [-0.2390312, 0.0980841, -0.9660453, -0.4409559... -0.074121  0.052016   \n",
       "\n",
       "      gyr_z    labels                            person  \n",
       "0  0.035234  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "1  0.061471  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "2  0.050830  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "3  0.059497  standing  ARS_Maria_Real_Sitting_Heading_2  \n",
       "4  0.067737  standing  ARS_Maria_Real_Sitting_Heading_2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2188965, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the current labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standing                                       724542\n",
       "walking                                        369227\n",
       "sitting                                        353225\n",
       "lying                                          169309\n",
       "running                                         90294\n",
       "walking upstairs                                34574\n",
       "TRANS-standing-falling                          29139\n",
       "walking downstairs                              29079\n",
       "jumping                                         28440\n",
       "TRANS-getting up                                24153\n",
       "TRANS-lying-falling                             21466\n",
       "TRANS-standing-walking upstairs                 21149\n",
       "TRANS-falling-standing                          20582\n",
       "TRANS-standing-sitting                          19460\n",
       "TRANS-walking-standing                          16328\n",
       "TRANS-walking downstairs-standing               14559\n",
       "TRANS-TRANS-going down-TRANS-getting up         14360\n",
       "TRANS-standing-running                          14044\n",
       "TRANS-standing-jumping forward                  13184\n",
       "falling                                         11902\n",
       "TRANS-running-standing                          11552\n",
       "TRANS-sitting-walking                           10552\n",
       "TRANS-going down                                 9910\n",
       "TRANS-walking upstairs-walking upstairs          9878\n",
       "TRANS-walking downstairs-walking downstairs      9109\n",
       "TRANS-falling-lying                              9006\n",
       "TRANS-accelerating                               8576\n",
       "TRANS-jumping vertically-standing                8125\n",
       "TRANS-lying-standing                             7215\n",
       "jumping vertically                               6357\n",
       "TRANS-sitting-standing                           6353\n",
       "jumping forward                                  5909\n",
       "TRANS-walking upstairs-walking downstairs        5384\n",
       "TRANS-standing-walking                           5307\n",
       "TRANS-standing-standing                          5199\n",
       "jumping backward                                 4788\n",
       "TRANS-jumping forward-standing                   4689\n",
       "TRANS-jumping backward-standing                  4654\n",
       "TRANS-jumping forward-jumping forward            4367\n",
       "TRANS-jumping vertically-jumping backward        4291\n",
       "TRANS-standing-jumping vertically                3771\n",
       "TRANS-standing-jumping backward                  3659\n",
       "TRANS-sitting-TRANS-getting up                   3430\n",
       "TRANS-TRANS-getting up-standing                  3350\n",
       "TRANS-jumping forward-jumping vertically         3128\n",
       "TRANS-walking upstairs-standing                  2572\n",
       "TRANS-deccelerating                              2294\n",
       "TRANS-standing-lying                             1807\n",
       "TRANS-jumping-standing                           1590\n",
       "TRANS-standing-walking downstairs                1546\n",
       "TRANS-jumping vertically-jumping vertically       650\n",
       "TRANS-TRANS-going down-sitting                    424\n",
       "TRANS-jumping-jumping                             328\n",
       "TRANS-running-TRANS-deccelerating                 179\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_counts = df['labels'].value_counts()\n",
    "#activity_counts.loc[~activity_counts.index.str.startswith('TRANS')]\n",
    "activity_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets merge together some activities:\n",
    "* jumping forward, jumping, jumping backward, jumping vertically = jumping\n",
    "* walking upstairs, walking downstairs, walking = walking\n",
    "\n",
    "And then for an initial analysis lets *not* consider the transition periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['labels'] = df['labels'].where(~df['labels'].isin(['jumping forward', 'jumping backward', 'jumping vertically']), 'jumping')\n",
    "df['labels'] = df['labels'].where(~df['labels'].isin(['walking upstairs', 'walking downstairs']), 'walking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 361319 transition frames, at 100Hz they are approx 60min of data\n"
     ]
    }
   ],
   "source": [
    "# check how many transients there are, before removing them from the dataset\n",
    "trans_count = df.loc[df['labels'].str.startswith('TRANS')].shape[0]\n",
    "print('There are {} transition frames, at 100Hz they are approx {}min of data'.format(trans_count, round(trans_count/100/60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f88ed9e9a58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAEMCAYAAACx033FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVPn/S7+Q5LvJNmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88f0e5ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove the transients\n",
    "df = df.loc[~df['labels'].str.startswith('TRANS')]\n",
    "activity_counts = df['labels'].value_counts()\n",
    "sns.barplot(x=activity_counts.index, y=activity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standing    121.0\n",
       "walking      72.0\n",
       "sitting      59.0\n",
       "lying        28.0\n",
       "running      15.0\n",
       "jumping       8.0\n",
       "falling       2.0\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minutes of each activity\n",
    "round(activity_counts / 100 / 60)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# compute the sensor measures in the global frame\n",
    "def to_global_frame(row):\n",
    "    attitude = np.array(row['attitude']).reshape(3,3)\n",
    "    acceleration = np.array([row.acc_x, row.acc_y, row.acc_z])\n",
    "    gyro = np.array([row.gyr_x, row.gyr_y, row.gyr_z])\n",
    "    \n",
    "    # global frame conversions\n",
    "    acc_gf = np.dot(attitude.T, acceleration)\n",
    "    gyro_gf = np.dot(attitude.T, gyro)\n",
    "    \n",
    "    row['acc_x_gf'] = acc_gf[0]\n",
    "    row['acc_y_gf'] = acc_gf[1]\n",
    "    row['acc_z_gf'] = acc_gf[2]\n",
    "    \n",
    "    row['gyr_x_gf'] = gyro_gf[0]\n",
    "    row['gyr_y_gf'] = gyro_gf[1]\n",
    "    row['gyr_z_gf'] = gyro_gf[2]\n",
    "    \n",
    "    return row\n",
    "\n",
    "df = df.apply(to_global_frame, axis=1)\n",
    "df = df.drop('attitude', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to test in future\n",
    "* keep transients\n",
    "* normalizing sensor values\n",
    "* data augmentation of underrepresented classes\n",
    "* test with global frame\n",
    "* reduce sampling rate to a value lower than 100Hz\n",
    "* variable frame size?\n",
    "* framing on person and activity, not only activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_zeros(df, stride, window):\n",
    "    label = df['labels'].iloc[0]\n",
    "    if df.shape[0] > window:\n",
    "        print('uno')\n",
    "        n = math.floor((df.shape[0]-window)/stride) + 1\n",
    "        remain = stride * n - (df.shape[0] - window)\n",
    "    else:\n",
    "        print('due')\n",
    "        remain = window - df.shape[0]\n",
    "    print('have to add {} zeros'.format(remain))\n",
    "    dfb = pd.DataFrame(data = np.zeros((remain, df.shape[1])), columns=df.columns)\n",
    "    dfb['labels'] = label\n",
    "    return df.append(dfb)\n",
    "\n",
    "def framing_range(start, end, stride, window, initialize=False):\n",
    "    if initialize:\n",
    "        return 0, start+window\n",
    "    # updates start and end positions considering stride and window size\n",
    "    start = end-stride\n",
    "    end = start+window\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing  standing\n",
      "shape is (724542, 9)\n",
      "uno\n",
      "have to add 2 zeros\n",
      "shape after is (724544, 9)\n",
      "doing  sitting\n",
      "shape is (353225, 9)\n",
      "uno\n",
      "have to add 55 zeros\n",
      "shape after is (353280, 9)\n",
      "doing  falling\n",
      "shape is (11902, 9)\n",
      "uno\n",
      "have to add 2 zeros\n",
      "shape after is (11904, 9)\n",
      "doing  lying\n",
      "shape is (169309, 9)\n",
      "uno\n",
      "have to add 35 zeros\n",
      "shape after is (169344, 9)\n",
      "doing  jumping\n",
      "shape is (45494, 9)\n",
      "uno\n",
      "have to add 10 zeros\n",
      "shape after is (45504, 9)\n",
      "doing  walking\n",
      "shape is (432880, 9)\n",
      "uno\n",
      "have to add 16 zeros\n",
      "shape after is (432896, 9)\n",
      "doing  running\n",
      "shape is (90294, 9)\n",
      "uno\n",
      "have to add 10 zeros\n",
      "shape after is (90304, 9)\n"
     ]
    }
   ],
   "source": [
    "window = 128\n",
    "stride = 64\n",
    "x = []\n",
    "y = []\n",
    "# cycle through each unique activity\n",
    "activities = df['labels'].unique()\n",
    "#count = 0\n",
    "for a in activities:\n",
    "    print('doing ', a)\n",
    "    dfa = df.loc[df['labels'] == a]\n",
    "    # check if padding is needed\n",
    "    print('shape is', dfa.shape)\n",
    "    if dfa.shape[0] % stride != 0:\n",
    "        dfa = append_zeros(dfa, stride, window)\n",
    "    print('shape after is', dfa.shape)\n",
    "        \n",
    "    start, end = framing_range(0, 0, stride, window, initialize=True)\n",
    "    while end != dfa.shape[0]:\n",
    "        current = dfa.iloc[start:end]\n",
    "        data = np.dstack([\n",
    "            current['acc_x'],\n",
    "            current['acc_y'],\n",
    "            current['acc_z'],\n",
    "            current['gyr_x'],\n",
    "            current['gyr_y'],\n",
    "            current['gyr_z']\n",
    "            ])\n",
    "        x += data.tolist()\n",
    "        y += [a] * data.shape[0]\n",
    "        # update start and end window indexes\n",
    "        start, end = framing_range(start, end, stride, window)\n",
    "    \n",
    "    #count += 1\n",
    "    #if count == 3:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28545, 128, 6)\n",
      "28545 28545\n"
     ]
    }
   ],
   "source": [
    "print(np.array(x).shape)\n",
    "print(len(y), len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting and saving train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28545, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding of the labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_int_encoded = le.fit_transform(y)\n",
    "y_int_encoded = np.array(y_int_encoded).reshape(len(y_int_encoded), 1)\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "y_ohe = ohe.fit_transform(y_int_encoded)\n",
    "y_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(x), y_ohe,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22836, 128, 6) (22836, 7)\n",
      "(5709, 128, 6) (5709, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just testing that train-test splitting was successful and kept classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standing    0.396532\n",
       "walking     0.236889\n",
       "sitting     0.193309\n",
       "lying       0.092626\n",
       "running     0.049361\n",
       "jumping     0.024838\n",
       "falling     0.006446\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = pd.Series(y)\n",
    "ys.value_counts()/ys.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.396523\n",
       "6    0.236907\n",
       "4    0.193335\n",
       "2    0.092617\n",
       "3    0.049352\n",
       "1    0.024829\n",
       "0    0.006437\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_train = [argmax(t) for t in y_train]\n",
    "ys_train = pd.Series(ys_train)\n",
    "ys_train.value_counts()/ys_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.396567\n",
       "6    0.236819\n",
       "4    0.193204\n",
       "2    0.092661\n",
       "3    0.049396\n",
       "1    0.024873\n",
       "0    0.006481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_test = [argmax(t) for t in y_test]\n",
    "ys_test = pd.Series(ys_test)\n",
    "ys_test.value_counts()/ys_test.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class proportions are maintained both in test and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all the files\n",
    "with h5py.File('train.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=x_train)\n",
    "    hf.create_dataset(\"y\",  data=y_train)\n",
    "with h5py.File('test.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=x_test)\n",
    "    hf.create_dataset(\"y\",  data=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22836, 7) (22836, 7)\n",
      "(22836, 128, 6) (22836, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('train.h5', 'r') as hf:\n",
    "    x = hf['x'][:]\n",
    "    y = hf['y'][:]\n",
    "print(y.shape, y_train.shape)\n",
    "print(x.shape, x_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
